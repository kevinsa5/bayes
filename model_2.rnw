The basic model we assumed last time is rarely the most applicable to real-life data analysis.  In general, there will be some measurement error (that is not necessarily constant across measurements) associated with the dataset in addition to scatter from other variables.  Let's generate some data that reflects this:

<<>>=
N = 25
true_x = runif(N,0,10)
true_slope = 1
true_intercept = 0
scatter = 1
true_y = rnorm(N, true_slope * true_x + true_intercept, scatter)
# known measurement uncertainties
x_sigma = rlnorm(N, -2, 0.5)
y_sigma = rlnorm(N, -2, 0.5)
obs_x = rnorm(N, true_x, x_sigma)
obs_y = rnorm(N, true_y, y_sigma)

@ 

<<fig.pos="H", fig.height=5, fig.width=5>>=
plot(obs_x, obs_y)
segments(obs_x, obs_y - 2*y_sigma, obs_x, obs_y + 2*y_sigma)
segments(obs_x - 2*x_sigma, obs_y, obs_x + 2*x_sigma, obs_y)
@

Clearly, the group scatter is larger than the individual measurement error bars allow, implying that one or more unmeasured variables are influencing the y values.  The model we'll use is a linear relationship between y and x, with (uniform) measurement error on both y and x and additional scatter in y.  The JAGS code is as follows:  

<<>>=
model_string = "
  model {
    # priors:
    a ~ dunif(0,5)
    b ~ dunif(-10,10)
    sigma ~ dunif(0,3)
    
    # structure:
    for (i in 1:N) {
        # the true x:
        x[i] ~ dunif(0,10)
        # the observed x:
        obs_x[i] ~ dnorm(x[i], pow(x_sigma[i],-2))
    
        # y, as it would be if it only depended on the true x:
        y[i] = a*x[i] + b
        # y, with the effect of the unmeasured confounding variable
        y_scatter[i] ~ dnorm(y[i], pow(sigma,-2))
        # y, with the confounding variable, with observational error:
        obs_y[i] ~ dnorm(y_scatter[i], pow(y_sigma[i],-2))
    }
  }
"
@ 
 
Now we proceed as before:  feed the data and model structure into JAGS and look at the output:

<<>>=
model = jags.model(file = textConnection(model_string), 
                   data = list('obs_x' = obs_x,
                               'x_sigma' = x_sigma,
                               'obs_y' = obs_y,
                               'y_sigma' = y_sigma,
                               'N' = N),
                   n.chains = 1,
                   n.adapt = 1000,
                   inits = list('.RNG.name' = 'base::Mersenne-Twister', 
                                '.RNG.seed' = 1))

output = coda.samples(model = model,
                      variable.names = c("a", "b", "sigma"), 
                      n.iter=1000,
                      thin=1)
summary(output)
plot(output)
@
